{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5665 images were loaded with their names and labeles\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read ground truth values for all 500k images\n",
    "ground_truth = np.genfromtxt('gt_train.csv', delimiter=',', dtype=['u4', 'U50'])\n",
    "\n",
    "# Put image titles and their labels in a dictionary for easy retrieval\n",
    "# Format: [imageNumber:Label]. Ex: [43123:'pedestrian']\n",
    "\n",
    "gt = {}\n",
    "for img in ground_truth:\n",
    "    gt[img[0]] = img[1]\n",
    "    \n",
    "# Load images and put in a dictionary. [name:image]\n",
    "images = []\n",
    "names = []\n",
    "labels = []\n",
    "for file in glob.glob(\"sub_train/*.jpg\"):\n",
    "    img = cv2.imread(file) # Read image\n",
    "    name = int(file[10:-4]) # File name\n",
    "    images.append(img)\n",
    "    names.append(name)\n",
    "    labels.append(gt[name])\n",
    "\n",
    "print(len(images), \"images were loaded with their names and labeles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute hog features\n",
    "def hog(img):\n",
    "    cell_size = (4, 4)  # h x w in pixels\n",
    "    block_size = (4, 4)  # h x w in cells\n",
    "    nbins = 8  # number of orientation bins\n",
    "\n",
    "    # create HoG Object\n",
    "    # winSize is the size of the image cropped to an multiple of the cell size\n",
    "    hog = cv2.HOGDescriptor(_winSize=(img.shape[1] // cell_size[1] * cell_size[1],\n",
    "                                      img.shape[0] // cell_size[0] * cell_size[0]),\n",
    "                            _blockSize=(block_size[1] * cell_size[1],\n",
    "                                        block_size[0] * cell_size[0]),\n",
    "                            _blockStride=(cell_size[1], cell_size[0]),\n",
    "                            _cellSize=(cell_size[1], cell_size[0]),\n",
    "                            _nbins=nbins)\n",
    "\n",
    "    n_cells = (img.shape[0] // cell_size[0], img.shape[1] // cell_size[1])\n",
    "\n",
    "    # Compute HoG features\n",
    "    hog_feats = hog.compute(img)\\\n",
    "                   .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                            n_cells[0] - block_size[0] + 1,\n",
    "                            block_size[0], block_size[1], nbins) \\\n",
    "                   .transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n",
    "    \n",
    "    # hog_feats now contains the gradient amplitudes for each direction,for each cell of its group for each group.\n",
    "    # Indexing is by rows then columns.\n",
    "\n",
    "    # computation for BlockNorm\n",
    "    gradients = np.full((n_cells[0], n_cells[1], 8), 0, dtype=float)\n",
    "    cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "\n",
    "    for off_y in range(block_size[0]):\n",
    "        for off_x in range(block_size[1]):\n",
    "            gradients[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                      off_x:n_cells[1] - block_size[1] + off_x + 1] += \\\n",
    "                hog_feats[:, :, off_y, off_x, :]\n",
    "            cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                       off_x:n_cells[1] - block_size[1] + off_x + 1] += 1\n",
    "\n",
    "    # Average gradients\n",
    "    gradients /= cell_count\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute HoG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the hogs list:  (5665, 1152) 1152\n"
     ]
    }
   ],
   "source": [
    "# Now the images are of diffrent sizes. We might need to fill the smaller images with zeros\n",
    "def fill(arr, max_len):\n",
    "    x = np.zeros(abs(len(arr) - max_len))\n",
    "    return np.concatenate((arr,x), axis=0)\n",
    "\n",
    "hogs_temp = []\n",
    "#calculate hog for each image\n",
    "max_len = 0\n",
    "for image in images:\n",
    "    #the classifier takes 2d training data. hog produces 3d so we flatten the result to make it 1d.. then we\n",
    "    #group all hogs in one list to make a 2d list\n",
    "    \n",
    "    # [REVEIW] resize because knn expects all data to be symetric\n",
    "    grad = hog(cv2.resize(image, (50, 50))).flatten()\n",
    "#     grad = hog(image).flatten()\n",
    "    if len(grad) > max_len:\n",
    "        max_len = len(grad)\n",
    "    hogs_temp.append(grad)\n",
    "\n",
    "#convert the HoGs array to np array to be processed\n",
    "hogs_temp = np.array(hogs_temp)\n",
    "hogs = hogs_temp\n",
    "\n",
    "# In case we need to fill the smaller images with zeros. For now we just resize them\n",
    "# hogs = []\n",
    "# for h in hogs_temp:\n",
    "#     new = fill(h,max_len)\n",
    "#     hogs.append(new)\n",
    "# hogs = np.array(hogs)\n",
    "\n",
    "print('Shape of the hogs list: ',hogs.shape, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data and Classify using KNN and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN is 917 out of 1417 , percentage: % 64.71418489767113\n",
      "Accuracy of SVM is 777 out of 1417 , percentage: % 54.83415666901905\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import  train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(hogs, labels, test_size=0.25)\n",
    "\n",
    "########################################################\n",
    "## KNN CLASSIFIER\n",
    "knn = knc(n_neighbors = 3)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "p = knn.predict(X_test)\n",
    "\n",
    "# Measure accuracy\n",
    "# IT'S NOT ACCURATE BECAUSE WE RESIZE IMAGES.. FIND A WAY TO FIT WITHOUT RESIZING\n",
    "i = 0\n",
    "for x in range(len(p)):\n",
    "    if p[x] == y_test[x]:\n",
    "        i += 1\n",
    "print('Accuracy of KNN is', i, 'out of', len(X_test), ', percentage: %', 100*i/len(X_test))\n",
    "########################################################\n",
    "\n",
    "\n",
    "########################################################\n",
    "## SVM CLASSIFIER\n",
    "# https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "# Create svm Linear object\n",
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "lin_clf.fit(X_train, y_train)\n",
    "\n",
    "p_svm = lin_clf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "k = 0\n",
    "for x in range(len(p)):\n",
    "    if p_svm[x] == y_test[x]:\n",
    "        k += 1\n",
    "print('Accuracy of SVM is', k, 'out of', len(X_test), ', percentage: %', 100*k/len(X_test))\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
